{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11337930,"sourceType":"datasetVersion","datasetId":7092765}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install vncorenlp\n!pip install transformers torch\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:02:34.812139Z","iopub.execute_input":"2025-04-09T10:02:34.812336Z","iopub.status.idle":"2025-04-09T10:02:45.361822Z","shell.execute_reply.started":"2025-04-09T10:02:34.812317Z","shell.execute_reply":"2025-04-09T10:02:45.360887Z"}},"outputs":[{"name":"stdout","text":"Collecting vncorenlp\n  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vncorenlp) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vncorenlp) (2025.1.31)\nBuilding wheels for collected packages: vncorenlp\n  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645932 sha256=e0a0c462903ca22b40ac57788dfa2e0f1ec07ccc491e8e3455a6a43dc0712f73\n  Stored in directory: /root/.cache/pip/wheels/5d/d9/b3/41f6c6b1ab758561fd4aab55dc0480b9d7a131c6aaa573a3fa\nSuccessfully built vncorenlp\nInstalling collected packages: vncorenlp\nSuccessfully installed vncorenlp-1.0.3\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:02:45.362986Z","iopub.execute_input":"2025-04-09T10:02:45.363244Z","iopub.status.idle":"2025-04-09T10:02:46.405228Z","shell.execute_reply.started":"2025-04-09T10:02:45.363222Z","shell.execute_reply":"2025-04-09T10:02:46.404596Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\n\n# T·∫£i tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n\n# T·∫£i m√¥ h√¨nh pretrained PhoBERT (encoder)\nmodel = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:02:46.407136Z","iopub.execute_input":"2025-04-09T10:02:46.407482Z","iopub.status.idle":"2025-04-09T10:03:12.872994Z","shell.execute_reply.started":"2025-04-09T10:02:46.407460Z","shell.execute_reply":"2025-04-09T10:03:12.871702Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad58e2973b504098979e608bf12eb105"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5bf0c1c0aed4003a635eaf693d052d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b083ae9fdd341ae8a456884518083f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6243abdf348b4b259cd1516cb3c31f6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9cd73e93987433fb31a55a113549c81"}},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"**READ DATA*> ***","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_excel(\"/kaggle/input/vnexpress/TopicModeling_Final.xlsx\", engine='openpyxl')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:12.875551Z","iopub.execute_input":"2025-04-09T10:03:12.877221Z","iopub.status.idle":"2025-04-09T10:03:14.140320Z","shell.execute_reply.started":"2025-04-09T10:03:12.877192Z","shell.execute_reply":"2025-04-09T10:03:14.139474Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                    Category  \\\n0         VƒÉn h√≥a & l·ªëi s·ªëng   \n1      Kinh doanh & qu·∫£n tr·ªã   \n2            Y t·∫ø & s·ª©c kh·ªèe   \n3     Ch√≠nh tr·ªã & ch√≠nh s√°ch   \n4         VƒÉn h√≥a & l·ªëi s·ªëng   \n...                      ...   \n3328              M√¥i tr∆∞·ªùng   \n3329   Kinh doanh & qu·∫£n tr·ªã   \n3330   Kinh doanh & qu·∫£n tr·ªã   \n3331     Gi√°o d·ª•c & tri th·ª©c   \n3332      VƒÉn h√≥a & l·ªëi s·ªëng   \n\n                                                Content  \n0     B√°i ƒê√≠nh c·ªï t·ª± l√† ng√¥i ch√πa ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n...  \n1     V·∫≠n ƒë·ªông vi√™n c·ªßa Singapore c√≥ th·ªÉ l√† lu·∫≠t s∆∞,...  \n2     ƒê·∫ßu nƒÉm h·ªçc m·ªõi, t√¥i c√¢n th·ª≠ chi·∫øc ba l√¥ c·ªßa c...  \n3     ‚ÄúT√¢m t∆∞ c·ªßa t√¥i c√°i g√¨ lu·∫≠t kh√¥ng c·∫•m th√¨ ph·∫£i...  \n4     M·∫π v·ªÅ nh√†, l∆∞ng √°o ƒë·∫´m m·ªì h√¥i, ng·ªìi ƒë·∫øm nh·ªØng ...  \n...                                                 ...  \n3328  Ch√∫ng ta ƒëang r·ª≠a tay theo c√°ch r·∫•t kh√°c v·ªõi m...  \n3329  T√¥i g·∫∑p Chokchai Koisrichai - gi√°m ƒë·ªëc, nh√† ƒëi...  \n3330  Su·ªët bao nƒÉm t√¥i ·ªü nh√† thu√™ v√¨ kh√¥ng bi·∫øt sau ...  \n3331  T√¥i v·ª´a ƒëi kh·∫£o s√°t m·ªôt s·ªë tr∆∞·ªùng h·ªçc ·ªü m·ªôt hu...  \n3332  Khi ch√∫ng t√¥i quy√™n g√≥p gi√∫p b√† con S√†i G√≤n ƒëa...  \n\n[3333 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>VƒÉn h√≥a &amp; l·ªëi s·ªëng</td>\n      <td>B√°i ƒê√≠nh c·ªï t·ª± l√† ng√¥i ch√πa ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kinh doanh &amp; qu·∫£n tr·ªã</td>\n      <td>V·∫≠n ƒë·ªông vi√™n c·ªßa Singapore c√≥ th·ªÉ l√† lu·∫≠t s∆∞,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Y t·∫ø &amp; s·ª©c kh·ªèe</td>\n      <td>ƒê·∫ßu nƒÉm h·ªçc m·ªõi, t√¥i c√¢n th·ª≠ chi·∫øc ba l√¥ c·ªßa c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ch√≠nh tr·ªã &amp; ch√≠nh s√°ch</td>\n      <td>‚ÄúT√¢m t∆∞ c·ªßa t√¥i c√°i g√¨ lu·∫≠t kh√¥ng c·∫•m th√¨ ph·∫£i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>VƒÉn h√≥a &amp; l·ªëi s·ªëng</td>\n      <td>M·∫π v·ªÅ nh√†, l∆∞ng √°o ƒë·∫´m m·ªì h√¥i, ng·ªìi ƒë·∫øm nh·ªØng ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3328</th>\n      <td>M√¥i tr∆∞·ªùng</td>\n      <td>Ch√∫ng ta ƒëang r·ª≠a tay theo c√°ch r·∫•t kh√°c v·ªõi m...</td>\n    </tr>\n    <tr>\n      <th>3329</th>\n      <td>Kinh doanh &amp; qu·∫£n tr·ªã</td>\n      <td>T√¥i g·∫∑p Chokchai Koisrichai - gi√°m ƒë·ªëc, nh√† ƒëi...</td>\n    </tr>\n    <tr>\n      <th>3330</th>\n      <td>Kinh doanh &amp; qu·∫£n tr·ªã</td>\n      <td>Su·ªët bao nƒÉm t√¥i ·ªü nh√† thu√™ v√¨ kh√¥ng bi·∫øt sau ...</td>\n    </tr>\n    <tr>\n      <th>3331</th>\n      <td>Gi√°o d·ª•c &amp; tri th·ª©c</td>\n      <td>T√¥i v·ª´a ƒëi kh·∫£o s√°t m·ªôt s·ªë tr∆∞·ªùng h·ªçc ·ªü m·ªôt hu...</td>\n    </tr>\n    <tr>\n      <th>3332</th>\n      <td>VƒÉn h√≥a &amp; l·ªëi s·ªëng</td>\n      <td>Khi ch√∫ng t√¥i quy√™n g√≥p gi√∫p b√† con S√†i G√≤n ƒëa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3333 rows √ó 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# B∆∞·ªõc 1: Chuy·ªÉn ch·ªØ th∆∞·ªùng, strip v√† chu·∫©n h√≥a unicode\nimport unicodedata\n\ndef clean_label(label):\n    label = unicodedata.normalize('NFC', label)\n    label = label.lower().strip()\n    label = label.replace(\"  \", \" \")  # n·∫øu c√≥ double space\n    return label\n\ndf['Category_clean'] = df['Category'].apply(clean_label)\n\n# B∆∞·ªõc 2: Mapping v·ªÅ nh√£n chu·∫©n (t√™n ƒë·∫πp)\ncategory_mapping = {\n    'vƒÉn h√≥a & l·ªëi s·ªëng': 'VƒÉn h√≥a & l·ªëi s·ªëng',\n    'ch√≠nh tr·ªã & ch√≠nh s√°ch': 'Ch√≠nh tr·ªã & ch√≠nh s√°ch',\n    'kinh doanh & qu·∫£n tr·ªã': 'Kinh doanh & qu·∫£n tr·ªã',\n    'gi√°o d·ª•c & tri th·ª©c': 'Gi√°o d·ª•c & tri th·ª©c',\n    'y t·∫ø & s·ª©c kh·ªèe': 'Y t·∫ø & s·ª©c kh·ªèe',\n    'm√¥i tr∆∞·ªùng': 'M√¥i tr∆∞·ªùng'\n    }\n\n# B∆∞·ªõc 3: G√°n l·∫°i nh√£n cu·ªëi\ndf['Category_standard'] = df['Category_clean'].map(category_mapping)\ndf['Category_standard'].value_counts()\n\ndf = df.drop(columns=['Category_clean', 'Category'])\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:14.141190Z","iopub.execute_input":"2025-04-09T10:03:14.141776Z","iopub.status.idle":"2025-04-09T10:03:14.169354Z","shell.execute_reply.started":"2025-04-09T10:03:14.141751Z","shell.execute_reply":"2025-04-09T10:03:14.168596Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                Content  \\\n0     B√°i ƒê√≠nh c·ªï t·ª± l√† ng√¥i ch√πa ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n...   \n1     V·∫≠n ƒë·ªông vi√™n c·ªßa Singapore c√≥ th·ªÉ l√† lu·∫≠t s∆∞,...   \n2     ƒê·∫ßu nƒÉm h·ªçc m·ªõi, t√¥i c√¢n th·ª≠ chi·∫øc ba l√¥ c·ªßa c...   \n3     ‚ÄúT√¢m t∆∞ c·ªßa t√¥i c√°i g√¨ lu·∫≠t kh√¥ng c·∫•m th√¨ ph·∫£i...   \n4     M·∫π v·ªÅ nh√†, l∆∞ng √°o ƒë·∫´m m·ªì h√¥i, ng·ªìi ƒë·∫øm nh·ªØng ...   \n...                                                 ...   \n3328  Ch√∫ng ta ƒëang r·ª≠a tay theo c√°ch r·∫•t kh√°c v·ªõi m...   \n3329  T√¥i g·∫∑p Chokchai Koisrichai - gi√°m ƒë·ªëc, nh√† ƒëi...   \n3330  Su·ªët bao nƒÉm t√¥i ·ªü nh√† thu√™ v√¨ kh√¥ng bi·∫øt sau ...   \n3331  T√¥i v·ª´a ƒëi kh·∫£o s√°t m·ªôt s·ªë tr∆∞·ªùng h·ªçc ·ªü m·ªôt hu...   \n3332  Khi ch√∫ng t√¥i quy√™n g√≥p gi√∫p b√† con S√†i G√≤n ƒëa...   \n\n           Category_standard  \n0         VƒÉn h√≥a & l·ªëi s·ªëng  \n1      Kinh doanh & qu·∫£n tr·ªã  \n2            Y t·∫ø & s·ª©c kh·ªèe  \n3     Ch√≠nh tr·ªã & ch√≠nh s√°ch  \n4         VƒÉn h√≥a & l·ªëi s·ªëng  \n...                      ...  \n3328              M√¥i tr∆∞·ªùng  \n3329   Kinh doanh & qu·∫£n tr·ªã  \n3330   Kinh doanh & qu·∫£n tr·ªã  \n3331     Gi√°o d·ª•c & tri th·ª©c  \n3332      VƒÉn h√≥a & l·ªëi s·ªëng  \n\n[3333 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Content</th>\n      <th>Category_standard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B√°i ƒê√≠nh c·ªï t·ª± l√† ng√¥i ch√πa ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n...</td>\n      <td>VƒÉn h√≥a &amp; l·ªëi s·ªëng</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V·∫≠n ƒë·ªông vi√™n c·ªßa Singapore c√≥ th·ªÉ l√† lu·∫≠t s∆∞,...</td>\n      <td>Kinh doanh &amp; qu·∫£n tr·ªã</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ƒê·∫ßu nƒÉm h·ªçc m·ªõi, t√¥i c√¢n th·ª≠ chi·∫øc ba l√¥ c·ªßa c...</td>\n      <td>Y t·∫ø &amp; s·ª©c kh·ªèe</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>‚ÄúT√¢m t∆∞ c·ªßa t√¥i c√°i g√¨ lu·∫≠t kh√¥ng c·∫•m th√¨ ph·∫£i...</td>\n      <td>Ch√≠nh tr·ªã &amp; ch√≠nh s√°ch</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M·∫π v·ªÅ nh√†, l∆∞ng √°o ƒë·∫´m m·ªì h√¥i, ng·ªìi ƒë·∫øm nh·ªØng ...</td>\n      <td>VƒÉn h√≥a &amp; l·ªëi s·ªëng</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3328</th>\n      <td>Ch√∫ng ta ƒëang r·ª≠a tay theo c√°ch r·∫•t kh√°c v·ªõi m...</td>\n      <td>M√¥i tr∆∞·ªùng</td>\n    </tr>\n    <tr>\n      <th>3329</th>\n      <td>T√¥i g·∫∑p Chokchai Koisrichai - gi√°m ƒë·ªëc, nh√† ƒëi...</td>\n      <td>Kinh doanh &amp; qu·∫£n tr·ªã</td>\n    </tr>\n    <tr>\n      <th>3330</th>\n      <td>Su·ªët bao nƒÉm t√¥i ·ªü nh√† thu√™ v√¨ kh√¥ng bi·∫øt sau ...</td>\n      <td>Kinh doanh &amp; qu·∫£n tr·ªã</td>\n    </tr>\n    <tr>\n      <th>3331</th>\n      <td>T√¥i v·ª´a ƒëi kh·∫£o s√°t m·ªôt s·ªë tr∆∞·ªùng h·ªçc ·ªü m·ªôt hu...</td>\n      <td>Gi√°o d·ª•c &amp; tri th·ª©c</td>\n    </tr>\n    <tr>\n      <th>3332</th>\n      <td>Khi ch√∫ng t√¥i quy√™n g√≥p gi√∫p b√† con S√†i G√≤n ƒëa...</td>\n      <td>VƒÉn h√≥a &amp; l·ªëi s·ªëng</td>\n    </tr>\n  </tbody>\n</table>\n<p>3333 rows √ó 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from sklearn.utils import resample\n\nmax_count = df['Category_standard'].value_counts().max()\nbalanced_dfs = []\n\nfor label in df['Category_standard'].unique():\n    group = df[df['Category_standard'] == label]\n    resampled = resample(group, replace=True, n_samples=max_count, random_state=42)\n    balanced_dfs.append(resampled)\n\ndf = pd.concat(balanced_dfs).sample(frac=1, random_state=42).reset_index(drop=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:14.170190Z","iopub.execute_input":"2025-04-09T10:03:14.170465Z","iopub.status.idle":"2025-04-09T10:03:14.193617Z","shell.execute_reply.started":"2025-04-09T10:03:14.170442Z","shell.execute_reply":"2025-04-09T10:03:14.192969Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import unicodedata\nimport re\nimport string\nimport pandas as pd\nfrom transformers import AutoTokenizer\n\n# Load PhoBERT tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n\n# Load stopwords t·ª´ file \"vietnamese-stopwords.txt\"\ndef load_stopwords(filepath):\n    with open(\"/kaggle/input/vnexpress/vietnamese-stopwords.txt\", encoding='utf-8') as f:\n        stopwords = set(line.strip() for line in f if line.strip())\n\n    return stopwords\n\nstopwords = load_stopwords(\"vietnamese-stopwords.txt\")\n\n# 1. Chu·∫©n h√≥a unicode NFC\ndef normalize_unicode(text):\n    return unicodedata.normalize('NFC', text)\n\n# 2. L√†m s·∫°ch vƒÉn b·∫£n: vi·∫øt th∆∞·ªùng, b·ªè s·ªë, d·∫•u c√¢u, kho·∫£ng tr·∫Øng th·ª´a\ndef text_normalizer(text):\n    text = text.lower()\n    text = re.sub(r'\\d+', '', text)  \n    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n    text = re.sub(\"\\s+\", \" \", text).strip()\n    return text\n\n# 3. Lo·∫°i b·ªè stopwords\ndef remove_stopwords(text, stopwords):\n    tokens = text.split()\n    filtered = [word for word in tokens if word not in stopwords]\n    return \" \".join(filtered)\n\n# 4. Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n th√†nh vƒÉn b·∫£n s·∫°ch (kh√¥ng m√£ h√≥a)\ndef clean_text_for_phobert(text, stopwords):\n    text = normalize_unicode(text)\n    text = text_normalizer(text)\n    text = remove_stopwords(text, stopwords)\n    return text\n\n# 5. Tokenize th√†nh input_ids\ndef encode_text(text, max_len=256):\n    return tokenizer.encode(\n        text,\n        max_length=max_len,\n        truncation=True,\n        padding='max_length'\n    )\n\n# --- √Åp d·ª•ng l√™n DataFrame ---\n# df l√† DataFrame ƒë√£ c√≥ c·ªôt 'Content'\n\n# T·∫°o c·ªôt vƒÉn b·∫£n ƒë√£ x·ª≠ l√Ω\ndf['Content_cleaned'] = df['Content'].apply(lambda x: clean_text_for_phobert(x, stopwords))\n\n# T·∫°o c·ªôt input_ids cho PhoBERT\ndf['input_ids'] = df['Content_cleaned'].apply(lambda x: encode_text(x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:14.194319Z","iopub.execute_input":"2025-04-09T10:03:14.194503Z","iopub.status.idle":"2025-04-09T10:03:33.549119Z","shell.execute_reply.started":"2025-04-09T10:03:14.194487Z","shell.execute_reply":"2025-04-09T10:03:33.548482Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['Category_standard'])  \nnum_labels = len(le.classes_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:33.549946Z","iopub.execute_input":"2025-04-09T10:03:33.550237Z","iopub.status.idle":"2025-04-09T10:03:33.556319Z","shell.execute_reply.started":"2025-04-09T10:03:33.550207Z","shell.execute_reply":"2025-04-09T10:03:33.555462Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_final = df.drop(columns = ['Content', 'Category_standard', 'Content_cleaned'])\ndf_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:33.558670Z","iopub.execute_input":"2025-04-09T10:03:33.558981Z","iopub.status.idle":"2025-04-09T10:03:33.767007Z","shell.execute_reply.started":"2025-04-09T10:03:33.558953Z","shell.execute_reply":"2025-04-09T10:03:33.766147Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                              input_ids  label\n0     [0, 441, 9866, 1560, 1294, 4721, 1103, 2935, 2...      2\n1     [0, 2404, 6928, 2487, 229, 1824, 3078, 7564, 6...      2\n2     [0, 328, 2201, 328, 9667, 2710, 1713, 12053, 8...      2\n3     [0, 61610, 10893, 49592, 1701, 564, 61610, 353...      0\n4     [0, 13397, 409, 109, 441, 1171, 2497, 2194, 61...      2\n...                                                 ...    ...\n4759  [0, 4368, 1430, 1895, 14294, 418, 119, 289, 74...      1\n4760  [0, 238, 222, 4698, 1746, 401, 940, 4698, 1031...      4\n4761  [0, 2925, 2792, 1197, 9645, 1080, 30768, 2183,...      0\n4762  [0, 286, 9393, 2288, 18116, 176, 853, 2615, 85...      3\n4763  [0, 235, 5963, 2546, 681, 808, 2546, 5717, 307...      2\n\n[4764 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 441, 9866, 1560, 1294, 4721, 1103, 2935, 2...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 2404, 6928, 2487, 229, 1824, 3078, 7564, 6...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 328, 2201, 328, 9667, 2710, 1713, 12053, 8...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 61610, 10893, 49592, 1701, 564, 61610, 353...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0, 13397, 409, 109, 441, 1171, 2497, 2194, 61...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4759</th>\n      <td>[0, 4368, 1430, 1895, 14294, 418, 119, 289, 74...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4760</th>\n      <td>[0, 238, 222, 4698, 1746, 401, 940, 4698, 1031...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4761</th>\n      <td>[0, 2925, 2792, 1197, 9645, 1080, 30768, 2183,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4762</th>\n      <td>[0, 286, 9393, 2288, 18116, 176, 853, 2615, 85...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4763</th>\n      <td>[0, 235, 5963, 2546, 681, 808, 2546, 5717, 307...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>4764 rows √ó 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# === Chia t·∫≠p d·ªØ li·ªáu train - val - test\ntrain_val_df, test_df = train_test_split(df_final, test_size=0.15, random_state=42, stratify=df_final['label'])\ntrain_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42, stratify=train_val_df['label'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:33.768071Z","iopub.execute_input":"2025-04-09T10:03:33.768294Z","iopub.status.idle":"2025-04-09T10:03:33.803561Z","shell.execute_reply.started":"2025-04-09T10:03:33.768274Z","shell.execute_reply":"2025-04-09T10:03:33.802674Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass PhoBertDataset(Dataset):\n    def __init__(self, data):\n        self.input_ids = data['input_ids'].tolist()\n        self.labels = data['label'].tolist()\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n            'attention_mask': torch.tensor([1 if id != 1 else 0 for id in self.input_ids[idx]], dtype=torch.long),\n            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n        }\n\n    def __len__(self):\n        return len(self.labels)\n\n\n# === Kh·ªüi t·∫°o datasets\ntrain_dataset = PhoBertDataset(train_df)\nval_dataset = PhoBertDataset(val_df)\ntest_dataset = PhoBertDataset(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:33.804493Z","iopub.execute_input":"2025-04-09T10:03:33.804867Z","iopub.status.idle":"2025-04-09T10:03:33.811354Z","shell.execute_reply.started":"2025-04-09T10:03:33.804836Z","shell.execute_reply":"2025-04-09T10:03:33.810506Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n# Kh√¥ng c·∫ßn import compute_class_weight n·∫øu kh√¥ng d√πng class weights\n# from sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n# === C·∫•u h√¨nh s·ªë l∆∞·ª£ng nh√£n\nnum_labels = df_final['label'].nunique()\n\n# === T·∫£i m√¥ h√¨nh PhoBERT\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"vinai/phobert-base\",\n    num_labels=num_labels\n)\n\n# === C·∫•u h√¨nh training\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=6,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_macro\",\n    greater_is_better=True,\n    logging_dir=\"./logs\",\n    report_to=\"none\"\n)\n\n# === H√†m t√≠nh metric\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    labels = p.label_ids\n    return {\n        \"accuracy\": accuracy_score(labels, preds),\n        \"precision_macro\": precision_score(labels, preds, average='macro'),\n        \"recall_macro\": recall_score(labels, preds, average='macro'),\n        \"f1_macro\": f1_score(labels, preds, average='macro'),\n    }\n\n# === D√πng Trainer m·∫∑c ƒë·ªãnh (kh√¥ng class weights)\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics\n)\n\n# === Hu·∫•n luy·ªán m√¥ h√¨nh\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:05:25.507788Z","iopub.execute_input":"2025-04-09T10:05:25.508125Z","iopub.status.idle":"2025-04-09T10:17:04.513686Z","shell.execute_reply.started":"2025-04-09T10:05:25.508101Z","shell.execute_reply":"2025-04-09T10:17:04.512908Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1296' max='1296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1296/1296 11:36, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision Macro</th>\n      <th>Recall Macro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.199600</td>\n      <td>0.902102</td>\n      <td>0.712171</td>\n      <td>0.711742</td>\n      <td>0.712693</td>\n      <td>0.709739</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.732900</td>\n      <td>0.745101</td>\n      <td>0.761513</td>\n      <td>0.762578</td>\n      <td>0.762053</td>\n      <td>0.757034</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.548200</td>\n      <td>0.654509</td>\n      <td>0.805921</td>\n      <td>0.807784</td>\n      <td>0.806203</td>\n      <td>0.806415</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.425000</td>\n      <td>0.631246</td>\n      <td>0.820724</td>\n      <td>0.819954</td>\n      <td>0.821167</td>\n      <td>0.817916</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.326000</td>\n      <td>0.639385</td>\n      <td>0.830592</td>\n      <td>0.829747</td>\n      <td>0.830923</td>\n      <td>0.828701</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.275700</td>\n      <td>0.624480</td>\n      <td>0.847039</td>\n      <td>0.845964</td>\n      <td>0.847344</td>\n      <td>0.845811</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1296, training_loss=0.5845523675282797, metrics={'train_runtime': 697.3696, 'train_samples_per_second': 29.606, 'train_steps_per_second': 1.858, 'total_flos': 2716192971380736.0, 'train_loss': 0.5845523675282797, 'epoch': 6.0})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# === ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test\ntest_metrics = trainer.evaluate(test_dataset)\nprint(\"Test set evaluation:\")\nfor k, v in test_metrics.items():\n    print(f\"{k}: {v:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:19:27.233481Z","iopub.execute_input":"2025-04-09T10:19:27.233872Z","iopub.status.idle":"2025-04-09T10:19:34.254435Z","shell.execute_reply.started":"2025-04-09T10:19:27.233845Z","shell.execute_reply":"2025-04-09T10:19:34.253733Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Test set evaluation:\neval_loss: 0.5624\neval_accuracy: 0.8573\neval_precision_macro: 0.8580\neval_recall_macro: 0.8572\neval_f1_macro: 0.8569\neval_runtime: 7.0133\neval_samples_per_second: 101.9490\neval_steps_per_second: 6.4160\nepoch: 6.0000\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"preds_output = trainer.predict(test_dataset)\npred_labels = np.argmax(preds_output.predictions, axis=1)\n\n# N·∫øu mu·ªën l∆∞u ƒë·ªÉ ph√¢n t√≠ch sau:\ntest_df[\"pred_label\"] = pred_labels\ntest_df.to_excel(\"test_predictions.xlsx\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:19:50.230254Z","iopub.execute_input":"2025-04-09T10:19:50.230590Z","iopub.status.idle":"2025-04-09T10:19:57.492266Z","shell.execute_reply.started":"2025-04-09T10:19:50.230559Z","shell.execute_reply":"2025-04-09T10:19:57.491273Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(test_df['label'], pred_labels)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(xticks_rotation=45)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T10:03:40.781797Z","iopub.status.idle":"2025-04-09T10:03:40.782084Z","shell.execute_reply":"2025-04-09T10:03:40.781957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}